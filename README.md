# DIMN
## Deep Information Mining Network for Person Re-identification for ICASSP2024
### Model details.
  We initially horizontally divide the human images into equal segments, ranging from 2 to 6 segments. Two segments represent the relationship between the upper and lower body parts and the entire body. Three segments represent the relationships between the head and chest, waist and abdomen, legs, and the entire body. Four segments represent the relationships between the head and neck, chest and abdomen, thighs, calves, and the entire body. Five segments represent the relationships between the head and neck, chest, abdomen, thighs, calves, and the entire body. Lastly, six segments represent the relationships between the head, chest, abdomen, thighs, calves, feet, and the entire body. For each segmented part, we thoroughly compute the corresponding relationships to fully exploit the information in the human image.<br>
![](https://github.com/meanlang/DIMN/blob/main/images/fig1.jpg)<br>
  Next, we feed the features from each individual part and the global feature into the network. We employ the RFM module to calculate the relationships between the individual parts and the whole. Finally, we concatenate the feature vectors of the corresponding parts with the feature vector of the whole, enabling the final feature vector of RFM to encompass both local and global information.As shown in the figure below, we demonstrate the fusion of upper-body information into the overall image context.<br>
![](https://github.com/meanlang/DIMN/blob/main/images/fig2.jpg)<br>
In the DFM module, we initially devised the first branch, which incorporates global and local features based on segmentation. This allowed us to achieve results similar to other methods. As shown in the following figure, we illustrate the characteristics of the feature vectors after the image is segmented into three parts and processed through the first branch of the DFM.
